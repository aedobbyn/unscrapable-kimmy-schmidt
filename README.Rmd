---
title: "README.Rmd"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Who am I

# What is web scraping?

# Tooling

### rvest

### Selenium

### SelectorGadget

# Politeness

# Versions

In a terminal:
```
brew cask install chromedriver
chromedriver --version
```

```{r}
wdman:::chrome_check(verbose = TRUE)
```

```{r}
chromedriver_versions <- binman::list_versions(appname = "chromedriver") %>% 
  .[[1]]
```

### Check which version of Chrome you have

`system` is a way to use the terminal through R. (You can replace this with whatever the path to Chrome is on your computer.)

```{r}
cmd <- "/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --version"
```


```{r}
chrome_version <- system(cmd, intern = TRUE) %>% 
  str_extract("[0-9\\.]+") %>% 
  str_sub(1L, 9L)
```

# Use the chromedriver version that matches your Chrome version
```{r}
version <- chromedriver_versions[which(
  str_detect(chromedriver_versions, chrome_version)
  )]
```



# Example

A random Wikipedia page

```{r}
next_xpath <- "/html/body/div/div/div[2]/button[1]"
```

```{r}
start_session <- function(url, browser = "chrome", port = 4444L, version) {
  if (port == 4444L) {
    while (any(!is.na(pingr::ping_port("localhost", port)))) {
      port <- port + 1
    }
  }
  
  # Start chrome driver
  wdman::chrome(
        port = as.integer(port),
        version = version,
        check = FALSE
      )
  
  # Create the driver object on localhost
  seleniumPipes::remoteDr(browserName = "chrome", port = port, version = version) %>%
    # Go to the url
    seleniumPipes::go(url)
}
```

```{r}
close_session <- function(
  server_name = ".deck_headless",
  server_environment = .GlobalEnv) {
  if (!exists(server_name, envir = server_environment)) {
    return(invisible())
  }

  server_environment[[server_name]]$stop()

  if (!sys.is_osx()) {
    display_pids <- sys.cmd("pgrep -f Xvfb") %>% .[. %in% sys.cmd("pgrep -f Xvfb")]
    if (length(display_pids) >= 1) for (pid in display_pids) sys.cmd(paste("kill -9", pid))
  }

  rm(list = server_name, envir = server_environment)
}
```



```{r}
url <- "https://en.wikipedia.org/wiki/Special:Random"

sess <- start_session(url, version = version)
```

```{r}
click <- function(sess, id_type, unique_id) {
  seleniumPipes::findElement(sess, id_type, unique_id) %>%
    seleniumPipes::elementClick()
}
```

```{r}
sess %>% 
  seleniumPipes::go(url)
```

```{r}
extract_html <- function(sess) {
  sess %>%
    seleniumPipes::getPageSource() %>%
    as.character() %>%
    xml2::read_html()
}
```

What if now we wanted all the links on this page? `rvest::html_text` would give us the text of the links. `rvest::html_attr` will give us attributes about the thing we're scraping.

```{r}
links <- sess %>% 
  extract_html() %>% 
  rvest::html_nodes("a") %>% 
  rvest::html_attr("href")
```

```{r}
text <- 
  sess %>% 
  extract_html() %>% 
  rvest::html_nodes("a") %>% 
  rvest::html_text()
```

```{r}
link_tbl <- 
  tibble(
    text = text,
    link = links
  ) %>% 
  print(n = nrow(.))
```

```{r}
link_tbl %>% 
  filter(
    str_detect(
      link, "^/wiki"
    )
  ) %>% 
  sample_n(1) %>% 
  pull(link)
```

# seleniumPipes has lots of useful functions like `back`, `refresh`, `getCurrentUrl`

# We can even take a screenshot

```{r}
sess %>% 
  seleniumPipes::takeScreenshot(
    file = glue::glue("{here::here()}/screenshot.png")
  )
```



```{r}
library(tidyverse)
library(rvest)
library(foodpls)

url <- "http://wikiroulette.co/"

driver <- seleniumPipes::remoteDr(browserName = "chrome")

sess <- start_session(url, version = version)

(xml <- 
  url %>% 
  xml2::read_html()
)
```

xml by itself is not very useful to us

```{r}
str(xml)
```

This is where `rvest` comes in. 

There are two types of nodes you can supply to `rvest::html_nodes`: CSS selectors and xpaths.

```{r}
?rvest::html_nodes
```


```{r}
(
  xml %>% 
    rvest::html_nodes()
)
```




```{r}
url <- "https://fivethirtyeight.com/"
```


```{r}
(xml <- 
  url %>% 
  xml2::read_html()
)
```

```{r}
(nodes <- xml %>% 
  rvest::html_nodes("a")
)
```

```{r}
(text <- nodes %>% 
  rvest::html_text())
```
```{r}
clean_html <- function(x) {
  x %>%
    str_squish() %>%
    str_remove_all("[\\n\\r\\t]")
}
```

```{r}
text[1:10]

text[1:10] %>% 
  clean_html()
```




